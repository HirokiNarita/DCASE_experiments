{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "import os\n",
    "\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-representation",
   "metadata": {},
   "source": [
    "# load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romance-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python default library\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# general analysis tool-kit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# original library\n",
    "sys.path.append('../../')\n",
    "import common as com\n",
    "import pytorch_modeler as modeler\n",
    "\n",
    "# etc\n",
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "\n",
    "# ML lib\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "#from umap import UMAP\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "\n",
    "import librosa\n",
    "import IPython\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-configuration",
   "metadata": {},
   "source": [
    "# load config and set logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = config['IO_OPTION']['OUTPUT_ROOT']+'/eval{0}.log'.format(datetime.date.today())\n",
    "logger = com.setup_logger(log_folder, '01_eval.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-effect",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "modeler.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equivalent-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/hiroki/HDD1TB/research/DCASE_experiments/SSL-Efficientnet_Barlow_Twins/dcase2021_task2/config.yaml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "# Setting I/O path\n",
    "############################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_dir = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_dir = INPUT_ROOT + \"/add_dev_data\"\n",
    "# machine type\n",
    "machine_types = os.listdir(dev_dir)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "TB_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/tb'\n",
    "OUT_FEATURE_DIR = OUTPUT_ROOT + '/extraction_features'\n",
    "OUT_SCORE_DIR = OUTPUT_ROOT + '/score'\n",
    "OUT_PRED_DIR = OUTPUT_ROOT + '/pred'\n",
    "#os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(TB_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_FEATURE_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_SCORE_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_PRED_DIR, exist_ok=True)\n",
    "# copy config\n",
    "shutil.copy('./config.yaml', OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-cradle",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "voluntary-occasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fan', 'gearbox', 'pump', 'slider', 'ToyCar', 'ToyTrain', 'valve']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loving-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['train', 'dev_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spectacular-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ext_data(machine_type):\n",
    "    input_path = f'{OUT_FEATURE_DIR}/{machine_type}_features.pkl'\n",
    "    ext_data = pd.read_pickle(input_path)\n",
    "    \n",
    "    return ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d84a4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ext_test_data(machine_type):\n",
    "    input_path = f'{OUT_FEATURE_DIR}/{machine_type}_features_test.pkl'\n",
    "    ext_data = pd.read_pickle(input_path)\n",
    "    \n",
    "    return ext_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ancient-bowling",
   "metadata": {},
   "source": [
    "machine_type = 'pump'\n",
    "input_path = f'{OUT_FEATURE_DIR}/{machine_type}_features.pkl'\n",
    "ext_data = pd.read_pickle(input_path)\n",
    "\n",
    "\n",
    "data_type = data_types[0]\n",
    "feats = ext_data[data_type]['features']\n",
    "labels = ext_data[data_type]['labels']\n",
    "data_types = [data_type] * len(ext_data[data_type]['labels'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "brazilian-adelaide",
   "metadata": {},
   "source": [
    "for i, data_type in enumerate(data_types):\n",
    "    if i == 0:\n",
    "        feats = ext_data[data_type]['features']\n",
    "        labels = ext_data[data_type]['labels']\n",
    "        data_types = [data_type] * len(ext_data[data_type]['labels'])\n",
    "    else:\n",
    "        feats = np.concatenate([feats, ext_data[data_type]['features']], axis=0)\n",
    "        labels = np.concatenate([labels, ext_data[data_type]['labels']], axis=0)\n",
    "        # data type\n",
    "        data_type = [data_type] * len(ext_data[data_type]['labels'])\n",
    "        data_types = data_types + data_type"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fluid-covering",
   "metadata": {},
   "source": [
    "wav_names = []\n",
    "for wav_name in ext_data[data_type]['wav_names']:\n",
    "    wav_names += wav_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "chubby-liver",
   "metadata": {},
   "source": [
    "len(wav_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "similar-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train datasets\n",
    "def get_target_names(wav_names):\n",
    "    target_names = []\n",
    "    for wav_name in wav_names:\n",
    "        if 'target' in wav_name:\n",
    "            target_names.append(wav_name)\n",
    "    \n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-adjustment",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-chambers",
   "metadata": {},
   "source": [
    "## calc MVG (multivariate Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nasty-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/hiroki/HDD1TB/research/DCASE_experiments/SSL-Efficientnet_Barlow_Twins/dcase2021_task2/extraction_features/gearbox_features.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e07bf1460fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmachine_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmachine_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mMVG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ext_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-00d7f4db24d4>\u001b[0m in \u001b[0;36mload_ext_data\u001b[0;34m(machine_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_ext_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{OUT_FEATURE_DIR}/{machine_type}_features.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mext_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/hiroki/HDD1TB/research/DCASE_experiments/SSL-Efficientnet_Barlow_Twins/dcase2021_task2/extraction_features/gearbox_features.pkl'"
     ]
    }
   ],
   "source": [
    "com.tic()\n",
    "\n",
    "MVG = {}\n",
    "for machine_type in machine_types:\n",
    "    MVG[machine_type] = {}\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    \n",
    "    mean = ext_data['train']['features'].mean(axis=0)\n",
    "    I = np.identity(ext_data['train']['features'].shape[1])\n",
    "    cov = np.cov(ext_data['train']['features'], rowvar=False) + 0.01 * I\n",
    "    MVG[machine_type]['mean'] = mean\n",
    "    MVG[machine_type]['cov'] = cov\n",
    "\n",
    "com.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e71eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(MVG[machine_types[0]]['cov'], aspect='auto', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-payroll",
   "metadata": {},
   "source": [
    "## estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba37376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mahalanobis(mean, cov, samples):\n",
    "    cov_inv = np.linalg.inv(MVG[machine_type]['cov'])\n",
    "    # load data\n",
    "    dists = [mahalanobis(sample, mean, cov_inv) for sample in samples]\n",
    "    # np.array\n",
    "    dists = np.array(dists)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70acf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd27802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_perID(describe_df, max_fpr=0.1):\n",
    "    # ユニークsectionを取得、昇順ソート\n",
    "    sections = np.sort(describe_df['section_types'].unique())\n",
    "\n",
    "    for section in sections:\n",
    "        per_section_df = describe_df[describe_df['section_types'] == section]\n",
    "        per_section_AUC = roc_auc_score(per_section_df['labels'], per_section_df['preds'])\n",
    "        per_section_pAUC = roc_auc_score(per_section_df['labels'], per_section_df['preds'], max_fpr=max_fpr)\n",
    "        # column = [AUC,pAUC], row = index\n",
    "        score_df = pd.DataFrame(np.stack([per_section_AUC, per_section_pAUC]), index=['AUC', 'pAUC']).T\n",
    "        # indexをsectionナンバーにrename\n",
    "        # column = [AUC,pAUC], row = [section]\n",
    "        score_df.index = [section]\n",
    "        if section == 0:\n",
    "            scores_df = score_df.copy()\n",
    "        else:\n",
    "            # 結合\n",
    "            scores_df = scores_df.append(score_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233b44c",
   "metadata": {},
   "source": [
    "## Calc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f33bc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 19:39:02,091 - 01_eval.py - INFO - CALC SCORE\n",
      "2021-08-12 19:39:02,092 - 01_eval.py - INFO - fan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>pAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>0.712300</td>\n",
       "      <td>0.533684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_01</th>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.497368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_02</th>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.543684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.623633</td>\n",
       "      <td>0.524912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_mean</th>\n",
       "      <td>0.616843</td>\n",
       "      <td>0.524141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUC      pAUC\n",
       "id_00   0.712300  0.533684\n",
       "id_01   0.553000  0.497368\n",
       "id_02   0.605600  0.543684\n",
       "mean    0.623633  0.524912\n",
       "h_mean  0.616843  0.524141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 19:39:10,056 - 01_eval.py - INFO - CALC SCORE\n",
      "2021-08-12 19:39:10,057 - 01_eval.py - INFO - gearbox\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b9de5037eae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# get MVG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtr_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtr_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# load samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean'"
     ]
    }
   ],
   "source": [
    "for i, machine_type in enumerate(machine_types):\n",
    "    logger.info('CALC SCORE')\n",
    "    logger.info(machine_type)\n",
    "    # get MVG\n",
    "    tr_mean = MVG[machine_type]['mean']\n",
    "    tr_cov = MVG[machine_type]['cov']\n",
    "    # load samples\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    for phase in ['valid_source', 'valid_target']:\n",
    "        # pred\n",
    "        samples = ext_data[phase]['features']\n",
    "        preds = calc_mahalanobis(tr_mean, tr_cov, samples)\n",
    "        section_types = com.get_section_types(ext_data[phase]['wav_names'])\n",
    "        # wavname + pred\n",
    "        preds_pd = np.stack([np.array(ext_data[phase]['wav_names']), preds], axis=1)\n",
    "        preds_pd = pd.DataFrame(preds_pd, columns=['wav_name', 'pred'])\n",
    "        preds_pd.to_csv(OUT_PRED_DIR + f'/pred_{machine_type}_{phase}.csv')\n",
    "        # dataframe作成\n",
    "        describe_df = com.get_pred_discribe(labels=ext_data[phase]['labels'],\n",
    "                                            preds=preds,\n",
    "                                            section_types=section_types,\n",
    "                                            wav_names=ext_data[phase]['wav_names'])\n",
    "        # スコア算出(AUC, pAUC)\n",
    "        scores_df = com.get_score_per_Section(describe_df, max_fpr=0.1)\n",
    "\n",
    "        # 結合(source + target)\n",
    "        scores_df = scores_df.rename(index=lambda num: 'id_0' + f'{num}')\n",
    "        all_scores_df = scores_df.copy()\n",
    "            \n",
    "    # 平均\n",
    "    mean_df = pd.DataFrame(all_scores_df.mean(axis=0)).T\n",
    "    mean_df.index = ['mean']\n",
    "    # 調和平均\n",
    "    hmean = scipy.stats.hmean(all_scores_df, axis=0)\n",
    "    hmean_df = pd.DataFrame(hmean, index=['AUC', 'pAUC']).T\n",
    "    hmean_df.index = ['h_mean']\n",
    "    # 結合\n",
    "    all_scores_df = all_scores_df.append(mean_df)\n",
    "    all_scores_df = all_scores_df.append(hmean_df)\n",
    "    # 出力\n",
    "    all_scores_df.to_csv(f'{OUT_SCORE_DIR}/{machine_type}_score.csv')\n",
    "    # display\n",
    "    display(all_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdeb4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 13:07:18,635 - 01_eval.py - INFO - CALC SCORE\n",
      "2021-08-11 13:07:18,636 - 01_eval.py - INFO - fan\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/hiroki/HDD1TB/research/DCASE_experiments/SSL-Efficientnet_frame257/dcase2021_task2/extraction_features/fan_features_test.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a9991e8e4f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtr_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# load samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ext_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'eval_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-a357bf2943d5>\u001b[0m in \u001b[0;36mload_ext_test_data\u001b[0;34m(machine_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_ext_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{OUT_FEATURE_DIR}/{machine_type}_features_test.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mext_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/hiroki/HDD1TB/research/DCASE_experiments/SSL-Efficientnet_frame257/dcase2021_task2/extraction_features/fan_features_test.pkl'"
     ]
    }
   ],
   "source": [
    "for i, machine_type in enumerate(machine_types):\n",
    "    logger.info('CALC SCORE')\n",
    "    logger.info(machine_type)\n",
    "    # get MVG\n",
    "    tr_mean = MVG[machine_type]['mean']\n",
    "    tr_cov = MVG[machine_type]['cov']\n",
    "    # load samples\n",
    "    ext_data = load_ext_test_data(machine_type)\n",
    "    for phase in ['eval_test']:\n",
    "        # pred\n",
    "        samples = ext_data[phase]['features']\n",
    "        preds = calc_mahalanobis(tr_mean, tr_cov, samples)\n",
    "        section_types = com.get_id(ext_data[phase]['wav_names'])\n",
    "        # wavname + pred\n",
    "        preds_pd = np.stack([preds, section_types, np.array(ext_data[phase]['wav_names'])], axis=1)\n",
    "        preds_pd = pd.DataFrame(preds_pd, columns=['preds', 'section_types', 'wav_names'])\n",
    "        preds_pd.to_csv(OUT_PRED_DIR + f'/pred_{machine_type}_{phase}.csv')\n",
    "        # dataframe作成\n",
    "#         describe_df = com.get_pred_discribe(labels=ext_data[phase]['labels'],\n",
    "#                                             preds=preds,\n",
    "#                                             section_types=section_types,\n",
    "#                                             wav_names=ext_data[phase]['wav_names'])\n",
    "#         # スコア算出(AUC, pAUC)\n",
    "#         scores_df = com.get_score_per_Section(describe_df, max_fpr=0.1)\n",
    "\n",
    "#         # 結合(source + target)\n",
    "#         scores_df = scores_df.rename(index=lambda num: 'id_0' + f'{num}')\n",
    "#         all_scores_df = scores_df.copy()\n",
    "            \n",
    "#     # 平均\n",
    "#     mean_df = pd.DataFrame(all_scores_df.mean(axis=0)).T\n",
    "#     mean_df.index = ['mean']\n",
    "#     # 調和平均\n",
    "#     hmean = scipy.stats.hmean(all_scores_df, axis=0)\n",
    "#     hmean_df = pd.DataFrame(hmean, index=['AUC', 'pAUC']).T\n",
    "#     hmean_df.index = ['h_mean']\n",
    "#     # 結合\n",
    "#     all_scores_df = all_scores_df.append(mean_df)\n",
    "#     all_scores_df = all_scores_df.append(hmean_df)\n",
    "#     # 出力\n",
    "#     all_scores_df.to_csv(f'{OUT_SCORE_DIR}/{machine_type}_score.csv')\n",
    "#     # display\n",
    "#     display(all_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74235468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-twins",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = calc_mahalanobis(tr_mean, tr_cov, samples)\n",
    "for machine_type in machine_types:\n",
    "    # get MVG\n",
    "    mean = MVG[machine_type]['mean']\n",
    "    cov_inv = np.linalg.inv(MVG[machine_type]['cov'])\n",
    "    # load data\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    # calc mahalanobis (Anomaly Score)\n",
    "    valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "    valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]\n",
    "    # np.array\n",
    "    valid_source_dists = np.array(valid_source_dists)\n",
    "    valid_target_dists = np.array(valid_target_dists)\n",
    "    # calc AUC\n",
    "    roc_auc = roc_auc_score(ext_data['valid_source']['labels'], valid_source_dists)\n",
    "    logger.info(f'{machine_type} valid_source AUC : {roc_auc}')\n",
    "    roc_auc = roc_auc_score(ext_data['valid_target']['labels'], valid_target_dists)\n",
    "    logger.info(f'{machine_type} valid_target AUC : {roc_auc}')\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.title(f'Source {machine_type}')\n",
    "    plt.plot(valid_source_dists, label='Anomaly Score')\n",
    "    plt.plot(ext_data['valid_source']['labels'], label='Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.title(f'Target {machine_type}')\n",
    "    plt.plot(valid_target_dists, label='Anomaly Score')\n",
    "    plt.plot(ext_data['valid_target']['labels'], label='Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-favorite",
   "metadata": {},
   "source": [
    "## calc GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data = load_ext_data(machine_types[6])\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm.fit(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.bic(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gmm.predict(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_covs = gmm.covariances_\n",
    "gmm_means = gmm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_covs = gmm.covariances_\n",
    "gmm_means = gmm.means_\n",
    "\n",
    "\n",
    "# calc mahalanobis (Anomaly Score)\n",
    "valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_type in machine_types:\n",
    "    # get MVG\n",
    "    mean = MVG[machine_type]['mean']\n",
    "    cov_inv = MVG[machine_type]['cov']\n",
    "    # load data\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    # calc mahalanobis (Anomaly Score)\n",
    "    valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "    valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]\n",
    "    # np.array\n",
    "    valid_source_dists = np.array(valid_source_dists)\n",
    "    valid_target_dists = np.array(valid_target_dists)\n",
    "    # calc AUC\n",
    "    roc_auc = roc_auc_score(ext_data['valid_source']['labels'], valid_source_dists)\n",
    "    logger.info(f'{machine_type} valid_source AUC : {roc_auc}')\n",
    "    roc_auc = roc_auc_score(ext_data['valid_target']['labels'], valid_target_dists)\n",
    "    logger.info(f'{machine_type} valid_target AUC : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_section_types = gmm.predict(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-statement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(section_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(gmm_section_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_dcase2021_task2)",
   "language": "python",
   "name": "conda_dcase2021_task2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
